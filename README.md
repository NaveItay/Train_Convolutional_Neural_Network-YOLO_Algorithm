# Train Convolutional Neural Network - YOLO Algorithm

In this project, we will talk about YoloV3 Architecture and how to train it on a custom dataset, I will explain step by step how to do it by using the Darknet framework.

– Introduction</p><p style="text-indent: 0pt;text-align: left;"><br/></p><ul id="l1"><li><p class="s5" style="padding-left: 124pt;text-indent: -18pt;line-height: 13pt;text-align: left;">What is Object Detection?</p></li><li><p class="s5" style="padding-left: 124pt;text-indent: -18pt;line-height: 13pt;text-align: left;">How does object detection work?</p></li><li><p class="s5" style="padding-left: 124pt;text-indent: -18pt;line-height: 13pt;text-align: left;">YOLO - You Only Look Once</p><ul id="l2"><li><p class="s5" style="padding-left: 160pt;text-indent: -18pt;line-height: 13pt;text-align: left;">YOLO v3.</p><ul id="l3"><li><p class="s5" style="padding-left: 196pt;text-indent: -18pt;line-height: 12pt;text-align: left;">Network Architecture</p></li><li><p class="s5" style="padding-left: 196pt;text-indent: -18pt;line-height: 13pt;text-align: left;">Feature Extractor</p></li><li><p class="s5" style="padding-left: 196pt;text-indent: -18pt;text-align: left;">Feature Detector</p></li><li><p class="s5" style="padding-left: 196pt;text-indent: -18pt;text-align: left;">Complete Network Architecture</p></li></ul></li></ul></li></ul><p style="text-indent: 0pt;text-align: left;"><br/></p><ul id="l4"><li><p class="s4" style="padding-left: 100pt;text-indent: -12pt;text-align: left;">– How to train YOLOv3 on a custom dataset.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><ul id="l5"><li><p class="s5" style="padding-left: 124pt;text-indent: -18pt;line-height: 13pt;text-align: left;">Data Preparation</p></li><li><p class="s5" style="padding-left: 124pt;text-indent: -18pt;line-height: 13pt;text-align: left;">Labelimg</p></li><li><p class="s5" style="padding-left: 124pt;text-indent: -18pt;line-height: 13pt;text-align: left;">Getting the files ready for training</p></li><li><p class="s5" style="padding-left: 124pt;text-indent: -18pt;line-height: 13pt;text-align: left;">Training the model by using Darknet</p></li><li><p class="s5" style="padding-left: 124pt;text-indent: -18pt;line-height: 13pt;text-align: left;">Use your custom weights for object detection.</p></li></ul></li></ul><p class="s6" style="padding-top: 3pt;padding-left: 88pt;text-indent: 0pt;text-align: center;">Introduction</p><p class="s7" style="padding-top: 22pt;padding-left: 88pt;text-indent: 0pt;line-height: 143%;text-align: left;">In this project, we will train a CNN model and explain step by step how to do it. But first, let&#39;s start with a brief explanation and then move on to the practical steps.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="254" height="254" alt="image" src="Convolutional Neural Network Project 3/Image_003.jpg"/></span></p><p class="s4" style="padding-top: 10pt;padding-left: 106pt;text-indent: 0pt;text-align: left;">- <b>What is Object Detection?</b></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 124pt;text-indent: 0pt;text-align: left;">Object detection is a technique that encompasses two tasks of <b>object classification </b>and <b>object localization</b><i>.</i></p><p style="padding-left: 124pt;text-indent: 0pt;text-align: left;">It is a model trained to detect the presence and location of multiple classes of objects.</p><p style="padding-left: 124pt;text-indent: 0pt;text-align: left;">This can be used on static images or even in real-time on videos.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s10" style="padding-top: 4pt;padding-left: 106pt;text-indent: 0pt;text-align: left;">- <b>How does object detection work?</b></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 43pt;text-indent: 0pt;text-align: left;"><a href="https://machinelearningmastery.com/object-recognition-with-deep-learning/" class="s13" target="_blank">Image from </a><a href="https://machinelearningmastery.com/object-recognition-with-deep-learning/" class="s12" target="_blank">machinelearningmastery</a><a href="https://machinelearningmastery.com/object-recognition-with-deep-learning/" class="s13" target="_blank">.</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 124pt;text-indent: 0pt;text-align: left;">Object detection finds the object and draws a bounding box around it.</p><p style="padding-left: 124pt;text-indent: 0pt;text-align: left;">This is a computer technology related to computer vision and image processing used for autonomous cars, face recognition, pedestrian detection, and more ...</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 124pt;text-indent: 0pt;text-align: left;">State-of-the-art algorithms are being used to detect objects e.g., R-CNN, Fast R-CNN, Faster R-CNN, Mask R-CNN, SSD, YOLO, etc. But we are specifically interested in YOLO.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><ul id="l6"><li><h1 style="padding-left: 124pt;text-indent: -18pt;text-align: left;">YOLO - You Only Look Once</h1><p style="padding-top: 12pt;padding-left: 124pt;text-indent: 0pt;text-align: left;">YOLO is one of the most powerful object detection algorithms.</p><p style="padding-left: 124pt;text-indent: 0pt;text-align: left;">Invented by Joseph Redmon, Santosh Divvala, Ross Girshick, and Ali Farhadi, so far it already has 5 different versions, we’re going to focus on YOLOv3.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><h1 style="padding-left: 124pt;text-indent: -18pt;text-align: left;">YOLOv3</h1><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 124pt;text-indent: 0pt;text-align: left;">YOLOv3 is more accurate, but a bit slower than its previous versions. This model includes multi-scale identification, some changes in the loss function, and a better feature extraction network.</p><ul id="l7"><li><h1 style="padding-top: 3pt;padding-left: 160pt;text-indent: -18pt;text-align: left;">Network Architecture</h1><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 160pt;text-indent: 0pt;text-align: left;">The network architecture is made up of two main components.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><ul id="l8"><li><h2 style="padding-left: 169pt;text-indent: -9pt;text-align: left;">Feature Extractor</h2></li><li><h2 style="padding-left: 169pt;text-indent: -9pt;text-align: left;">Feature Detector</h2><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 160pt;text-indent: 0pt;text-align: left;">The image is first received by the Feature Extractor which extracts &quot;features tables&quot; and then given to the Feature Detector which exports the processed image with the bounding boxes around the detected classes.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li></ul></li><li><h1 style="padding-left: 160pt;text-indent: -18pt;text-align: left;">Feature Extractor</h1><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 160pt;text-indent: 0pt;text-align: left;">In the project, we used a network with 53 convolution layers (Darknet-53).</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 202pt;text-indent: 0pt;text-align: left;"><span><img width="232" height="326" alt="image" src="Convolutional Neural Network Project 3/Image_004.jpg"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 163pt;text-indent: 0pt;text-align: left;"><a href="https://arxiv.org/pdf/1804.02767.pdf" style=" color: #757575; font-family:&quot;Times New Roman&quot;, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">This image is the darknet-53 architecture taken from </a><a href="https://arxiv.org/pdf/1804.02767.pdf" class="s12" target="_blank">YOLOv3: An Incremental Improvement</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 4pt;padding-left: 160pt;text-indent: 0pt;text-align: left;">This CNN is built with consecutive 3x3 and 1x1 convolution layers followed by a skip connection.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 160pt;text-indent: 0pt;text-align: left;">The 53 layers of the Darknet add another 53 layers to the detection head, meaning the basic architecture of YOLOv3 contains 106 layers making it a relatively larger architecture than the previous versions, although the processing time is a bit slower but improves the accuracy at the same time.</p><p style="padding-top: 3pt;padding-left: 160pt;text-indent: 0pt;text-align: left;">In our case, we would like to detect the classes with the locations, so in the extractor, there is a detection head.</p><p style="padding-left: 160pt;text-indent: 0pt;text-align: left;">The detection head is a multi-scale detection hence, we would need to extract features at multiple scales as well.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 160pt;text-indent: 0pt;text-align: left;">YOLOv3 extracts three feature vectors - (52x52), (26x26), and (13x13) while the tiny version extracts only (26x26) and (13x13).</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 160pt;text-indent: 0pt;text-align: left;">(52x52 for smaller objects, 26x26 for medium objects, and 13x13 would be used for the larger objects).</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 39pt;text-indent: 0pt;text-align: left;"><span><img width="687" height="317" alt="image" src="Convolutional Neural Network Project 3/Image_005.jpg"/></span></p><p class="s14" style="padding-left: 240pt;text-indent: 0pt;text-align: left;">Multi-scale Feature Extractor for a 416x416 image</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 160pt;text-indent: 0pt;text-align: left;">we define this matrix as a “grid” and assign anchor boxes to each cell of the grid. In other words, anchor boxes anchor to the grid cells, and they share the same centroid.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><h1 style="padding-top: 9pt;padding-left: 160pt;text-indent: -18pt;text-align: left;">Feature Detector</h1><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 160pt;text-indent: 0pt;text-align: left;">The Feature Detector eventual output of a fully convolutional network is done by applying 1x1 detection kernels on feature maps of three different sizes at three different places. The shape of the kernel is 1x1x(B*(5+C)).</p></li><li><h1 style="padding-top: 3pt;padding-left: 160pt;text-indent: -18pt;text-align: left;">Complete Network Architecture</h1><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="783" height="431" alt="image" src="Convolutional Neural Network Project 3/Image_006.jpg"/></span></p><p style="padding-left: 160pt;text-indent: 0pt;text-align: left;"><a href="https://towardsdatascience.com/%40ayoosh?source=post_page-----53fb7d3bfe6b----------------------" class="s15" target="_blank">Ayoosh Kathuria</a><span style=" color: #944F71; font-family:&quot;Times New Roman&quot;, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt;"> </span>made a very elaborate diagram that beautifully explains the complete architecture of YOLO v3 (Combining both, the extractor, and the detector).</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-top: 8pt;padding-left: 88pt;text-indent: 0pt;text-align: center;"><a href="https://towardsdatascience.com/yolo-v3-object-detection-53fb7d3bfe6b" style=" color: #757575; font-family:&quot;Times New Roman&quot;, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 9pt;" target="_blank">Diagram from </a><a href="https://towardsdatascience.com/yolo-v3-object-detection-53fb7d3bfe6b" class="s17" target="_blank">https://towardsdatascience.com/yolo-v3-object-detection-53fb7d3bfe6b</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s7" style="padding-top: 10pt;padding-left: 160pt;text-indent: 0pt;text-align: left;">As seen in the above diagram, where we take an example of a 416x416 image, the three scales where the detections are made are at the 82nd layer, 94th layer, and 106th layer.</p><p class="s7" style="padding-top: 6pt;padding-left: 160pt;text-indent: 0pt;text-align: left;">V3 architecture contains residual skipping and upsampling. The salient feature of the v3 is the detection capability on three different scales.</p><p class="s7" style="padding-left: 160pt;text-indent: 0pt;text-align: left;">YOLO is a fully convolutional network and its eventual output is generated by applying a 1 x 1 kernel on a feature map. In YOLO v3, the detection is done by applying 1 x 1 detection kernels on feature maps of three different sizes at three different places in the network.</p><p class="s7" style="padding-top: 6pt;padding-left: 160pt;text-indent: 0pt;text-align: left;">The multi-scale detector is used to ensure that the small objects are also detected in contrast to the previous versions.</p><p class="s18" style="padding-top: 3pt;padding-left: 88pt;text-indent: 0pt;text-align: center;">How to train YOLOv3 on a custom dataset</p></li></ul></li><li><p class="s8" style="padding-top: 22pt;padding-left: 124pt;text-indent: -18pt;text-align: left;">Data Preparation.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s7" style="padding-left: 124pt;text-indent: 0pt;text-align: left;">In this project, we download an entire episode of SpongeBob and then saved a frame every 60 frames to create the dataset.</p><p class="s7" style="padding-left: 124pt;text-indent: 0pt;text-align: left;">(vid2frames.py Script)</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 87pt;text-indent: 0pt;text-align: left;"><span><img width="559" height="275" alt="image" src="Convolutional Neural Network Project 3/Image_007.jpg"/></span></p><ul id="l9"><li><p style="padding-top: 11pt;padding-left: 130pt;text-indent: -7pt;text-align: left;"><span class="s19" style=" background-color: #F8F8F8;">160 ~ Photos of SpongeBob</span></p></li><li><p style="padding-left: 130pt;text-indent: -7pt;line-height: 12pt;text-align: left;"><span class="s19" style=" background-color: #F8F8F8;">98 ~ Photos of Squidward</span></p></li><li><p style="padding-left: 130pt;text-indent: -7pt;line-height: 12pt;text-align: left;"><span class="s19" style=" background-color: #F8F8F8;">80 ~ Pictures of MrKrabs</span></p></li><li><p style="padding-left: 130pt;text-indent: -7pt;text-align: left;"><span class="s19" style=" background-color: #F8F8F8;">50 ~ Pictures of Patrick</span></p></li><li><p style="padding-left: 130pt;text-indent: -7pt;text-align: left;"><span class="s19" style=" background-color: #F8F8F8;">35 ~ Photos of Plankton</span></p></li></ul><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s22" style="padding-left: 124pt;text-indent: 0pt;text-align: left;"><a href="https://storage.googleapis.com/openimages/web/index.html" class="s25" target="_blank">Another option, you can download ready-made datasets from </a>googleapis.com<a href="https://public.roboflow.com/" class="s25" target="_blank">, </a><a href="https://public.roboflow.com/" class="a" target="_blank">roboflow</a><span class="s23"> </span><span class="s7">and others...</span></p></li><li><p class="s8" style="padding-top: 3pt;padding-left: 124pt;text-indent: -18pt;text-align: left;">Labelimg.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 87pt;text-indent: 0pt;text-align: left;"><span><img width="558" height="303" alt="image" src="Convolutional Neural Network Project 3/Image_008.jpg"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s22" style="padding-top: 12pt;padding-left: 124pt;text-indent: 0pt;text-align: left;"><a href="https://github.com/microsoft/VoTT" style=" color: #292929; font-family:&quot;Times New Roman&quot;, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt;" target="_blank">There are many labeling tools like </a>VoTT<a href="https://cvat.org/" style=" color: black; font-family:&quot;Times New Roman&quot;, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt;" target="_blank">, </a>CVAT,<span class="s23"> </span><a href="https://github.com/tzutalin/labelImg" style=" color: #292929; font-family:&quot;Times New Roman&quot;, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt;" target="_blank">and </a>Labelimg<span class="p">.</span></p><p class="s23" style="padding-left: 124pt;text-indent: 0pt;text-align: left;"><a href="https://tzutalin.github.io/labelImg/" style=" color: #292929; font-family:&quot;Times New Roman&quot;, serif; font-style: normal; font-weight: normal; text-decoration: none; font-size: 12pt;" target="_blank">In this project, we performed using </a><a href="https://tzutalin.github.io/labelImg/" class="a" target="_blank">TZUTA LIN&#39;s</a> <span style=" color: #292929;">Labelimg software.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s23" style="padding-top: 4pt;padding-left: 124pt;text-indent: 0pt;text-align: left;"><a href="https://tzutalin.github.io/labelImg/" class="s25" target="_blank">We recommend Labelimg because it is popular and easy to use, you can download it from </a><a href="https://tzutalin.github.io/labelImg/" class="a" target="_blank">here</a> <span style=" color: #202020;">to Windows or Linux operating systems.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s24" style="padding-top: 4pt;padding-left: 73pt;text-indent: 0pt;text-align: center;">TIP:    <span class="s7">Shortcut keys can be used for quick and convenient labeling.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 128pt;text-indent: 0pt;text-align: left;"><span><img width="330" height="341" alt="image" src="Convolutional Neural Network Project 3/Image_009.jpg"/></span></p></li><li><p class="s8" style="padding-top: 3pt;padding-left: 124pt;text-indent: -18pt;text-align: left;">Getting the files ready for training.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s7" style="padding-top: 10pt;padding-left: 124pt;text-indent: 0pt;text-align: left;">After the labeling, we will see an image(JPG) and a text file with the same name, respectively.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 93pt;text-indent: 0pt;text-align: left;"><span><img width="550" height="263" alt="image" src="Convolutional Neural Network Project 3/Image_010.jpg"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s5" style="padding-left: 124pt;text-indent: 0pt;text-align: left;">** in YOLO, the format looks like this.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s5" style="padding-left: 160pt;text-indent: 0pt;line-height: 13pt;text-align: left;">0 0.645508 0.592448 0.134766 0.216146</p><p class="s5" style="padding-left: 160pt;text-indent: 0pt;line-height: 13pt;text-align: left;">2 0.756836 0.368490 0.138672 0.200521</p><p class="s5" style="padding-left: 160pt;text-indent: 0pt;text-align: left;">3 0.097656 0.563802 0.187500 0.513021</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s5" style="padding-left: 160pt;text-indent: 0pt;text-align: left;">[class index] [(x, y) coordinates] [width, height]</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s7" style="padding-left: 124pt;text-indent: 0pt;text-align: left;">Compress them to a zip folder and rename it to &quot;images.zip&quot;.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s7" style="padding-left: 124pt;text-indent: 0pt;text-align: left;">Create a folder named &quot;yolov3&quot; in Google Drive and put the dataset and train_yolov3 notebook in it.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 296pt;text-indent: 0pt;text-align: left;"><span><img width="274" height="196" alt="image" src="Convolutional Neural Network Project 3/Image_011.jpg"/></span></p></li><li><p class="s8" style="padding-top: 3pt;padding-left: 124pt;text-indent: -18pt;text-align: left;">Training the model by using Darknet</p></li></ul><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s22" style="padding-top: 10pt;padding-left: 124pt;text-indent: 0pt;text-align: left;"><a href="https://github.com/pjreddie/darknet" class="s25" target="_blank">Darknet is an open-source neural network framework written in C and CUDA. It is fast, easy to install, and supports CPU and GPU computation. You can find the source on </a>GitHub<span class="s7">.</span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="163" height="159" alt="image" src="Convolutional Neural Network Project 3/Image_012.jpg"/></span></p><p style="padding-left: 124pt;text-indent: 0pt;text-align: left;"><a href="https://pjreddie.com/darknet/yolo/" class="s25" target="_blank">Reference: </a><a href="https://pjreddie.com/darknet/yolo/" class="a" target="_blank">pjreddie.com</a><a href="https://pjreddie.com/darknet/yolo/" class="s25" target="_blank">.</a></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s7" style="padding-top: 8pt;padding-left: 124pt;text-indent: 0pt;text-align: left;">Now let&#39;s start with Google Colab Notebook.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="301" height="239" alt="image" src="Convolutional Neural Network Project 3/Image_013.jpg"/></span></p><p class="s7" style="padding-left: 124pt;text-indent: 0pt;text-align: left;">1. Make sure you enable GPU.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="275" height="176" alt="image" src="Convolutional Neural Network Project 3/Image_014.jpg"/></span></p><p class="s26" style="padding-left: 66pt;text-indent: 0pt;text-align: center;"></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><span><img width="342" height="215" alt="image" src="Convolutional Neural Network Project 3/Image_015.jpg"/></span></p><p class="s7" style="padding-top: 9pt;padding-left: 124pt;text-indent: 0pt;text-align: left;">2.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s7" style="padding-top: 11pt;padding-left: 124pt;text-indent: 0pt;text-align: left;">You can see that we got a Tesla K80 GPU using the 11.2 Cuda version. bad luck, sometimes I got the Tesla v100 <span class="s27">😉</span>.</p><ol id="l10"><li><p class="s7" style="padding-top: 3pt;padding-left: 142pt;text-indent: -18pt;text-align: left;">Connect Colab with Google Drive</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 143pt;text-indent: 0pt;text-align: left;"><span><img width="314" height="84" alt="image" src="Convolutional Neural Network Project 3/Image_016.jpg"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p class="s7" style="padding-top: 8pt;padding-left: 142pt;text-indent: -18pt;text-align: left;">Get the Darknet model</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 137pt;text-indent: 0pt;text-align: left;"><span><img width="422" height="70" alt="image" src="Convolutional Neural Network Project 3/Image_017.jpg"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p class="s7" style="padding-top: 7pt;padding-left: 142pt;text-indent: -18pt;text-align: left;">edit the .cfg to fit your needs based on your object detector.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 148pt;text-indent: 0pt;text-align: left;"><span><img width="549" height="188" alt="image" src="Convolutional Neural Network Project 3/Image_018.jpg"/></span></p><p class="s5" style="padding-top: 10pt;padding-left: 160pt;text-indent: -36pt;line-height: 147%;text-align: left;">** How to Configure Your Variables: width = 416</p><p class="s5" style="padding-left: 160pt;text-indent: 0pt;text-align: left;">height = 416</p><h4 style="padding-top: 5pt;padding-left: 160pt;text-indent: 0pt;text-align: left;">(these can be any multiple of 32, 416 is standard, you can sometimes improve results by making value larger like 608 but will slow down training).</h4><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s5" style="padding-left: 160pt;text-indent: 0pt;text-align: left;">Max_batches = (number of classes) * 2000</p><h4 style="padding-top: 5pt;padding-left: 160pt;text-indent: 0pt;text-align: left;">(but no less than 6000 so if you are training for 1, 2, or 3 classes it will be 6000, however, the detector for 5 classes would have max_batches=10000).</h4><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s5" style="padding-left: 160pt;text-indent: 0pt;text-align: left;">Steps = (80% of max_batches), (90% of max_batches)</p><h4 style="padding-top: 6pt;padding-left: 160pt;text-indent: 0pt;text-align: left;">(so, if your max_batches = 10000, then steps = 8000, 9000).</h4><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s5" style="padding-left: 160pt;text-indent: 0pt;text-align: left;">Filters = (number of classes + 5) * 3</p><h4 style="padding-top: 5pt;padding-left: 160pt;text-indent: 0pt;text-align: left;">(so, if you are training for one class then your filters = 18, but if you are training for 4 classes then your filters = 27).</h4><h3 style="padding-top: 4pt;padding-left: 160pt;text-indent: 0pt;text-align: left;">Optional: <span class="s5">If you run into memory issues or find the training taking a super long time. In each of the three yolo layers in the cfg, change one line from random = 1 to </span>random = 0 <span class="s5">to speed up training but slightly reduce the accuracy of the model. Will also help save memory if you run into any memory issues.</span></h3><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p class="s28" style="padding-left: 142pt;text-indent: -18pt;text-align: left;">Create your .names and .data files.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 88pt;text-indent: 0pt;text-align: left;"><span><img width="548" height="32" alt="image" src="Convolutional Neural Network Project 3/Image_019.jpg"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p class="s28" style="padding-left: 142pt;text-indent: -18pt;text-align: left;">Save .cfg and obj.names files in Google drive.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 114pt;text-indent: 0pt;text-align: left;"><span><img width="486" height="52" alt="image" src="Convolutional Neural Network Project 3/Image_020.jpg"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p class="s28" style="padding-left: 142pt;text-indent: -18pt;text-align: left;">Create a folder and unzip the image dataset.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 88pt;text-indent: 0pt;text-align: left;"><span><img width="552" height="56" alt="image" src="Convolutional Neural Network Project 3/Image_021.jpg"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p class="s28" style="padding-top: 9pt;padding-left: 142pt;text-indent: -18pt;text-align: left;">Create train.txt file.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 142pt;text-indent: 0pt;text-align: left;"><span><img width="346" height="85" alt="image" src="Convolutional Neural Network Project 3/Image_022.jpg"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p class="s7" style="padding-left: 142pt;text-indent: -18pt;text-align: left;">Download pre-trained weights.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 129pt;text-indent: 0pt;text-align: left;"><span><img width="444" height="35" alt="image" src="Convolutional Neural Network Project 3/Image_023.jpg"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s7" style="padding-left: 142pt;text-indent: 0pt;text-align: left;">For training, we use <span style=" color: #545454;">convolution </span>weights that are pre-trained on the ImageNet dataset.</p></li><li><p class="s7" style="padding-top: 3pt;padding-left: 145pt;text-indent: -21pt;text-align: left;">Finally, start training.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 130pt;text-indent: 0pt;text-align: left;"><span><img width="548" height="43" alt="image" src="Convolutional Neural Network Project 3/Image_024.jpg"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s7" style="padding-left: 76pt;text-indent: 0pt;text-align: center;">The training will take a long time, so take a great time to rest.</p><p style="text-indent: 0pt;text-align: left;"><br/></p><h3 style="padding-left: 196pt;text-indent: -54pt;text-align: left;">TIP: <span class="s5">Colab Cloud Service kicks you off if you are idle for too long (60-90 mins).</span></h3><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s5" style="padding-left: 196pt;text-indent: 0pt;text-align: left;">To avoid this, you can download auto-clicker software or make a python script.</p><p style="text-indent: 0pt;text-align: left;"><br/></p></li><li><p class="s7" style="padding-left: 142pt;text-indent: -18pt;text-align: left;">Testing - You can download the weights file to your local machine and check it on the validation data.</p></li></ol><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-left: 23pt;text-indent: 0pt;text-align: left;"><span><img width="320" height="181" alt="image" src="Convolutional Neural Network Project 3/Image_025.jpg"/></span>	<span><img width="320" height="180" alt="image" src="Convolutional Neural Network Project 3/Image_026.jpg"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p style="padding-left: 153pt;text-indent: 0pt;text-align: left;"><span><img width="382" height="206" alt="image" src="Convolutional Neural Network Project 3/Image_027.jpg"/></span></p><p style="text-indent: 0pt;text-align: left;"><br/></p><p class="s30" style="padding-left: 23pt;text-indent: 0pt;text-align: left;"><span><img width="316" height="177" alt="image" src="Convolutional Neural Network Project 3/Image_028.jpg"/></span>	<span><img width="316" height="177" alt="image" src="Convolutional Neural Network Project 3/Image_029.jpg"/></span></p><p class="s6" style="padding-top: 3pt;padding-left: 88pt;text-indent: 0pt;text-align: center;">References</p><ol id="l11"><li><p style="padding-top: 24pt;padding-left: 124pt;text-indent: -18pt;text-align: left;"><a href="https://pjreddie.com/media/files/papers/YOLOv3.pdf">https://pjreddie.com/media/files/papers/YOLOv3.pdf</a></p></li><li><p style="padding-top: 1pt;padding-left: 124pt;text-indent: -18pt;text-align: left;"><a href="https://machinelearningmastery.com/object-recognition-with-deep-learning/">https://machinelearningmastery.com/object-recognition-with-deep-learning/</a></p></li><li><p style="padding-top: 1pt;padding-left: 124pt;text-indent: -18pt;line-height: 108%;text-align: left;"><a href="https://towardsdatascience.com/digging-deep-into-yolo-v3-a-hands-on-guide-part-1-78681f2c7e29" class="a" target="_blank">https://towardsdatascience.com/digging-deep-into-yolo-v3-a-hands-on-guide-</a><a href="https://towardsdatascience.com/digging-deep-into-yolo-v3-a-hands-on-guide-part-1-78681f2c7e29" target="_blank"> part-1-78681f2c7e29</a></p></li><li><p style="padding-left: 124pt;text-indent: -18pt;line-height: 108%;text-align: left;"><a href="https://medium.com/%4095shanu/the-ultimate-yolo-guide-to-train-on-custom-dataset-e7095d084f0c" class="a" target="_blank">https://medium.com/@95shanu/the-ultimate-yolo-guide-to-train-on-custom-</a><a href="https://medium.com/%4095shanu/the-ultimate-yolo-guide-to-train-on-custom-dataset-e7095d084f0c" target="_blank"> dataset-e7095d084f0c</a></p></li><li><p style="padding-left: 124pt;text-indent: -18pt;line-height: 108%;text-align: left;"><a href="https://medium.com/analytics-vidhya/yolo-object-detection-made-easy-7b17cc3e782f" class="a" target="_blank">https://medium.com/analytics-vidhya/yolo-object-detection-made-easy-</a><a href="https://medium.com/analytics-vidhya/yolo-object-detection-made-easy-7b17cc3e782f" target="_blank"> 7b17cc3e782f</a></p></li><li><p style="padding-left: 124pt;text-indent: -18pt;line-height: 14pt;text-align: left;"><a href="https://github.com/tzutalin/labelImg">https://github.com/tzutalin/labelImg</a></p></li><li><p style="padding-top: 1pt;padding-left: 124pt;text-indent: -18pt;line-height: 109%;text-align: left;"><a href="https://learnopencv.com/training-yolov3-deep-learning-based-custom-object-detector/" class="a" target="_blank">https://learnopencv.com/training-yolov3-deep-learning-based-custom-object-</a><a href="https://learnopencv.com/training-yolov3-deep-learning-based-custom-object-detector/" target="_blank"> detector/</a></p></li><li><p style="padding-left: 124pt;text-indent: -18pt;line-height: 14pt;text-align: left;"><a href="https://github.com/AlexeyAB/darknet">https://github.com/AlexeyAB/darknet</a></p></li><li><p style="padding-top: 1pt;padding-left: 124pt;text-indent: -18pt;text-align: left;"><a href="https://en.wikipedia.org/wiki/Object_detection">https://en.wikipedia.org/wiki/Object_detection</a></p></li><li><p style="padding-top: 1pt;padding-left: 124pt;text-indent: -18pt;line-height: 108%;text-align: left;"><a href="https://prashantdandriyal.medium.com/decoding-yolov3-output-with-intel-openvinos-backend-part-1-a2a478cd93ca" class="a" target="_blank">https://prashantdandriyal.medium.com/decoding-yolov3-output-with-intel-</a><a href="https://prashantdandriyal.medium.com/decoding-yolov3-output-with-intel-openvinos-backend-part-1-a2a478cd93ca" target="_blank"> openvinos-backend-part-1-a2a478cd93ca</a></p></li></ol></body></html>



